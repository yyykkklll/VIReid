"""
main.py - PF-MGCD ä¸»å…¥å£ç¨‹åº (å®Œæ•´ä¿®å¤ç‰ˆ)

ä¿®å¤æ—¥å¿—:
1. [P0] å®Œå–„æ–­ç‚¹æ¢å¤é€»è¾‘ (Teacher + Scheduler + Memory Bank)
2. [P0] ä¿®å¤æµ‹è¯•æ¨¡å¼checkpoint keyå…¼å®¹æ€§é—®é¢˜
3. [P1] æ·»åŠ è®°å¿†åº“çŠ¶æ€æ£€æŸ¥å’Œæ¢å¤
4. åˆ é™¤é‡å¤çš„set_seedå‡½æ•°
5. æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Š

åŠŸèƒ½:
- å‚æ•°è§£æå’Œé…ç½®ç®¡ç†
- æ¨¡å‹åˆ›å»ºå’Œåˆå§‹åŒ–
- è®­ç»ƒ/æµ‹è¯•æµç¨‹æ§åˆ¶
- æ–­ç‚¹æ¢å¤å’Œä¿å­˜

ä½œè€…: PF-MGCD Team
æ—¥æœŸ: 2025-12-02
"""

import os
import sys
import argparse
import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# [ä¿®å¤] ä½¿ç”¨utils.pyçš„set_seedï¼Œåˆ é™¤æœ¬åœ°é‡å¤å®šä¹‰
from utils import set_seed


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        args: Namespaceå¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰è¶…å‚æ•°
    """
    parser = argparse.ArgumentParser(
        description='PF-MGCD for Visible-Infrared Person Re-Identification'
    )
    
    # ==================== åŸºç¡€è®¾ç½® ====================
    parser.add_argument('--dataset', type=str, default='sysu',
                        choices=['sysu', 'regdb', 'llcm'],
                        help='æ•°æ®é›†é€‰æ‹©: sysu(SYSU-MM01), regdb(RegDB), llcm(LLCM)')
    parser.add_argument('--data-path', type=str, default='./datasets',
                        help='æ•°æ®é›†æ ¹è·¯å¾„')
    parser.add_argument('--mode', type=str, default='train',
                        choices=['train', 'test'],
                        help='è¿è¡Œæ¨¡å¼: train(è®­ç»ƒ), test(æµ‹è¯•)')
    parser.add_argument('--resume', type=str, default='',
                        help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„ (ä¾‹å¦‚: checkpoints/sysu/epoch_50.pth)')
    parser.add_argument('--gpu', type=str, default='0',
                        help='ä½¿ç”¨çš„GPUç¼–å· (ä¾‹å¦‚: 0 æˆ– 0,1)')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­ (ç”¨äºå¯å¤ç°æ€§)')
    
    # ==================== PF-MGCDæ¨¡å‹å‚æ•° ====================
    parser.add_argument('--num-parts', type=int, default=6,
                        help='äººä½“éƒ¨ä»¶æ•°é‡K (é»˜è®¤6: å¤´-ä¸Šèº«-ä¸­èº«-ä¸‹èº«-è…¿éƒ¨-è„šéƒ¨)')
    parser.add_argument('--feature-dim', type=int, default=512,
                        help='è§£è€¦åçš„ç‰¹å¾ç»´åº¦D (Clean Baselineé»˜è®¤512)')
    parser.add_argument('--memory-momentum', type=float, default=0.9,
                        help='è®°å¿†åº“åŠ¨é‡æ›´æ–°ç³»æ•°m (èŒƒå›´0~1)')
    parser.add_argument('--temperature', type=float, default=3.0,
                        help='å›¾ä¼ æ’­Softmaxæ¸©åº¦T (è¶Šå¤§åˆ†å¸ƒè¶Šå¹³æ»‘)')
    parser.add_argument('--top-k', type=int, default=5,
                        help='å›¾ä¼ æ’­Top-Ké‚»å±…æ•°é‡ (ä¿ç•™æ¥å£å…¼å®¹)')
    parser.add_argument('--pretrained', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨ImageNeté¢„è®­ç»ƒçš„ResNetæƒé‡')
    
    # éª¨å¹²ç½‘ç»œä¸ç²¾åº¦
    parser.add_argument('--backbone', type=str, default='resnet50',
                        choices=['resnet50', 'resnet101', 'resnet152'],
                        help='ResNetéª¨å¹²ç½‘ç»œç±»å‹')
    parser.add_argument('--amp', action='store_true',
                        help='å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒAMP (A100æ¨è, å¯åŠ é€Ÿ2x)')
    
    # ==================== æ•°æ®é›†å‚æ•° ====================
    parser.add_argument('--num-classes', type=int, default=395,
                        help='ç±»åˆ«æ•°é‡N (è‡ªåŠ¨æ ¹æ®æ•°æ®é›†è®¾ç½®)')
    parser.add_argument('--num-workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½workerè¿›ç¨‹æ•°')
    parser.add_argument('--pid-numsample', type=int, default=8,
                        help='æ¯ä¸ªIDçš„æ ·æœ¬æ•° (ç”¨äºPKé‡‡æ ·)')
    parser.add_argument('--batch-pidnum', type=int, default=8,
                        help='æ¯batchçš„IDæ•° (batch_size = pid_numsample * batch_pidnum)')
    parser.add_argument('--test-batch', type=int, default=128,
                        help='æµ‹è¯•æ—¶çš„batchå¤§å°')
    parser.add_argument('--img-w', type=int, default=144,
                        help='è¾“å…¥å›¾åƒå®½åº¦')
    parser.add_argument('--img-h', type=int, default=288,
                        help='è¾“å…¥å›¾åƒé«˜åº¦')
    parser.add_argument('--relabel', action='store_true', default=True,
                        help='æ˜¯å¦é‡æ–°æ ‡æ³¨ID (å¼±ç›‘ç£åœºæ™¯)')
    parser.add_argument('--search-mode', type=str, default='all',
                        choices=['all', 'indoor'],
                        help='SYSUæ£€ç´¢æ¨¡å¼: all(å…¨éƒ¨æ‘„åƒå¤´), indoor(ä»…å®¤å†…)')
    parser.add_argument('--gall-mode', type=str, default='single',
                        choices=['single', 'multi'],
                        help='SYSU Galleryæ¨¡å¼: single(å•æ¬¡), multi(å¤šæ¬¡)')
    parser.add_argument('--test-mode', type=str, default='v2t',
                        choices=['v2t', 't2v'],
                        help='LLCMæµ‹è¯•æ¨¡å¼: v2t(å¯è§å…‰â†’çº¢å¤–), t2v(çº¢å¤–â†’å¯è§å…‰)')
    parser.add_argument('--trial', type=int, default=1,
                        help='RegDB trialç¼–å· (1~10)')
    
    # ==================== æŸå¤±å‡½æ•°æƒé‡ ====================
    parser.add_argument('--lambda-graph', type=float, default=0.1,
                        help='å›¾è’¸é¦æŸå¤±æƒé‡ Î»_graph')
    parser.add_argument('--lambda-orth', type=float, default=0.1,
                        help='æ­£äº¤æŸå¤±æƒé‡ Î»_orth (ä¿ç•™æ¥å£)')
    parser.add_argument('--lambda-mod', type=float, default=0.5,
                        help='æ¨¡æ€åˆ¤åˆ«æŸå¤±æƒé‡ Î»_mod (ä¿ç•™æ¥å£)')
    parser.add_argument('--lambda-triplet', type=float, default=0.5,
                        help='ä¸‰å…ƒç»„æŸå¤±æƒé‡ Î»_triplet')
    parser.add_argument('--label-smoothing', type=float, default=0.1,
                        help='æ ‡ç­¾å¹³æ»‘ç³»æ•° (èŒƒå›´0~1)')
    
    # ==================== è®­ç»ƒå‚æ•° ====================
    parser.add_argument('--total-epoch', type=int, default=120,
                        help='æ€»è®­ç»ƒè½®æ•°')
    parser.add_argument('--warmup-epochs', type=int, default=10,
                        help='Warmupè½®æ•° (å‰æœŸä¸å¯ç”¨Graph Loss)')
    parser.add_argument('--batch-size', type=int, default=64,
                        help='è®­ç»ƒæ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=0.00035,
                        help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--weight-decay', type=float, default=5e-4,
                        help='æƒé‡è¡°å‡ç³»æ•° (L2æ­£åˆ™)')
    parser.add_argument('--grad-clip', type=float, default=5.0,
                        help='æ¢¯åº¦è£å‰ªé˜ˆå€¼ (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)')
    
    # ==================== å­¦ä¹ ç‡è°ƒåº¦ ====================
    parser.add_argument('--lr-scheduler', type=str, default='cosine',
                        choices=['step', 'cosine', 'plateau'],
                        help='å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥')
    parser.add_argument('--lr-step', type=str, default='40,70',
                        help='StepLRçš„æ­¥é•¿ æˆ– MultiStepLRçš„é‡Œç¨‹ç¢‘ (é€—å·åˆ†éš”)')
    parser.add_argument('--lr-gamma', type=float, default=0.1,
                        help='StepLRçš„å­¦ä¹ ç‡è¡°å‡ç³»æ•°')
    
    # ==================== è®°å¿†åº“åˆå§‹åŒ– ====================
    parser.add_argument('--init-memory', action='store_true',
                        help='è®­ç»ƒå‰åˆå§‹åŒ–è®°å¿†åº“ (æ¨èå¼€å¯)')
    
    # ==================== ä¿å­˜å’Œæ—¥å¿— ====================
    parser.add_argument('--save-dir', type=str, default='./checkpoints',
                        help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--log-dir', type=str, default='./logs',
                        help='æ—¥å¿—ä¿å­˜ç›®å½•')
    parser.add_argument('--save-epoch', type=int, default=10,
                        help='æ¯éš”å¤šå°‘epochä¿å­˜æ¨¡å‹')
    parser.add_argument('--eval-epoch', type=int, default=5,
                        help='æ¯éš”å¤šå°‘epochè¯„ä¼°æ¨¡å‹')
    
    # ==================== æµ‹è¯•å‚æ•° ====================
    parser.add_argument('--model-path', type=str, default='',
                        help='æµ‹è¯•æ¨¡å‹è·¯å¾„ (ä¾‹å¦‚: checkpoints/best_model.pth)')
    parser.add_argument('--pool-parts', action='store_true',
                        help='æµ‹è¯•æ—¶æ˜¯å¦æ‹¼æ¥æ‰€æœ‰éƒ¨ä»¶ç‰¹å¾ (True: K*D, False: D)')
    parser.add_argument('--distance-metric', type=str, default='euclidean',
                        choices=['euclidean', 'cosine'],
                        help='è·ç¦»åº¦é‡æ–¹å¼')
    
    args = parser.parse_args()
    
    # æ ¹æ®æ•°æ®é›†è‡ªåŠ¨è®¾ç½®ç±»åˆ«æ•°
    if args.dataset == 'sysu':
        args.num_classes = 395
    elif args.dataset == 'regdb':
        args.num_classes = 206
    elif args.dataset == 'llcm':
        args.num_classes = 713
    
    return args


def main():
    """
    ä¸»å‡½æ•°
    """
    # ==================== 1. è§£æå‚æ•°å’Œç¯å¢ƒè®¾ç½® ====================
    args = parse_args()
    
    # è®¾ç½®GPUç¯å¢ƒ
    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # è®¾ç½®éšæœºç§å­ï¼ˆç¡®ä¿å¯å¤ç°æ€§ï¼‰
    set_seed(args.seed)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    os.makedirs(args.log_dir, exist_ok=True)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("="*70)
    print(" "*18 + "PF-MGCD Configuration (Bug Fixed)")
    print("="*70)
    print(f"{'Dataset':<20}: {args.dataset.upper()}")
    print(f"{'Mode':<20}: {args.mode.upper()}")
    print(f"{'Backbone':<20}: {args.backbone.upper()}")
    print(f"{'Mixed Precision':<20}: {'âœ… Enabled' if args.amp else 'âŒ Disabled'}")
    print(f"{'Num Parts':<20}: {args.num_parts}")
    print(f"{'Feature Dim':<20}: {args.feature_dim}")
    print(f"{'LR Schedule':<20}: {args.lr_scheduler}")
    print(f"{'Total Epochs':<20}: {args.total_epoch}")
    if args.resume:
        print(f"{'Resume':<20}: {args.resume}")
    print("="*70 + "\n")
    
    # ==================== 2. åˆ›å»ºæ¨¡å‹ ====================
    print("ğŸ”§ åˆ›å»ºPF-MGCD Studentæ¨¡å‹...")
    from models.pfmgcd_model import PF_MGCD
    
    model = PF_MGCD(
        num_parts=args.num_parts,
        num_identities=args.num_classes,
        feature_dim=args.feature_dim,
        memory_momentum=args.memory_momentum,
        temperature=args.temperature,
        top_k=args.top_k,
        pretrained=args.pretrained,
        backbone=args.backbone
    ).to(device)
    
    total_params = sum(p.numel() for p in model.parameters()) / 1e6
    print(f"âœ… Studentæ¨¡å‹å‚æ•°é‡: {total_params:.2f}M\n")
    
    # ==================== 3. è®­ç»ƒæ¨¡å¼ ====================
    if args.mode == 'train':
        # 3.1 åŠ è½½è®­ç»ƒæ•°æ®
        from datasets.dataloader_adapter import get_dataloader
        train_loader, _ = get_dataloader(args)
        print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(train_loader)} batches\n")
        
        # 3.2 åˆ›å»ºTeacheræ¨¡å‹ (Mean Teacheræ¶æ„)
        print("ğŸ”§ åˆ›å»ºMean Teacheræ¨¡å‹...")
        teacher_model = PF_MGCD(
            num_parts=args.num_parts,
            num_identities=args.num_classes,
            feature_dim=args.feature_dim,
            memory_momentum=args.memory_momentum,
            temperature=args.temperature,
            top_k=args.top_k,
            pretrained=False,  # Teacherä»Studentå¤åˆ¶æƒé‡
            backbone=args.backbone
        ).to(device)
        
        # åˆå§‹åŒ–Teacheræƒé‡ä¸ºStudentçš„å‰¯æœ¬
        teacher_model.load_state_dict(model.state_dict())
        
        # å†»ç»“Teacherå‚æ•°ï¼ˆä¸å‚ä¸æ¢¯åº¦ä¸‹é™ï¼Œä»…é€šè¿‡EMAæ›´æ–°ï¼‰
        for param in teacher_model.parameters():
            param.requires_grad = False
        
        print("âœ… Teacheræ¨¡å‹åˆå§‹åŒ–å®Œæˆ (æƒé‡å·²ä»Studentå¤åˆ¶)\n")
        
        # 3.3 åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=args.lr,
            weight_decay=args.weight_decay
        )
        
        # ==================== [ä¿®å¤] æ–­ç‚¹æ¢å¤é€»è¾‘ ====================
        start_epoch = 0
        scheduler_state_loaded = False
        
        if args.resume and os.path.isfile(args.resume):
            print(f"ğŸ“‚ åŠ è½½checkpoint: {args.resume}")
            checkpoint = torch.load(args.resume, map_location=device)
            
            # æ¢å¤epoch
            start_epoch = checkpoint.get('epoch', 0)
            print(f"   â””â”€ Epoch: {start_epoch}")
            
            # æ¢å¤Studentæ¨¡å‹
            if 'model' in checkpoint:
                model.load_state_dict(checkpoint['model'])
                print(f"   â””â”€ âœ… Studentæ¨¡å‹æƒé‡å·²æ¢å¤")
            else:
                raise KeyError("âŒ Checkpointä¸­ç¼ºå°‘'model'é”®!")
            
            # [ä¿®å¤] æ¢å¤Teacheræ¨¡å‹
            if 'teacher' in checkpoint and checkpoint['teacher'] is not None:
                teacher_model.load_state_dict(checkpoint['teacher'])
                print(f"   â””â”€ âœ… Teacheræ¨¡å‹æƒé‡å·²æ¢å¤")
            else:
                # é™çº§æ–¹æ¡ˆï¼šä»Studentå¤åˆ¶
                teacher_model.load_state_dict(model.state_dict())
                print(f"   â””â”€ âš ï¸  Checkpointä¸­æ— Teacheræƒé‡ï¼Œå·²ä»Studentå¤åˆ¶")
            
            # æ¢å¤ä¼˜åŒ–å™¨
            if 'optim' in checkpoint:
                optimizer.load_state_dict(checkpoint['optim'])
                print(f"   â””â”€ âœ… ä¼˜åŒ–å™¨çŠ¶æ€å·²æ¢å¤")
            
            # æ ‡è®°schedulerçŠ¶æ€
            if 'scheduler' in checkpoint and checkpoint['scheduler'] is not None:
                scheduler_state_loaded = True
                print(f"   â””â”€ âœ… SchedulerçŠ¶æ€å·²æ ‡è®°ä¸ºå¾…æ¢å¤")
            
            # [ä¿®å¤] æ£€æŸ¥è®°å¿†åº“çŠ¶æ€
            if hasattr(model, 'memory_bank'):
                num_initialized = model.memory_bank.initialized.sum().item()
                total_ids = model.memory_bank.num_identities
                print(f"   â””â”€ ğŸ“Š è®°å¿†åº“çŠ¶æ€: {num_initialized}/{total_ids} IDså·²åˆå§‹åŒ–")
                
                if num_initialized == 0:
                    print(f"   â””â”€ âš ï¸  è­¦å‘Š: è®°å¿†åº“æœªåˆå§‹åŒ–ï¼Œå°†åœ¨è®­ç»ƒå¼€å§‹å‰é‡æ–°åˆå§‹åŒ–")
            
            print(f"âœ… æ–­ç‚¹æ¢å¤å®Œæˆ! å°†ä»Epoch {start_epoch+1}ç»§ç»­è®­ç»ƒ\n")
        
        elif args.resume:
            print(f"âŒ æœªæ‰¾åˆ°checkpoint: {args.resume}\n")
        
        # 3.4 åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = None
        if args.lr_scheduler == 'step':
            if ',' in args.lr_step:
                # MultiStepLR
                milestones = [int(x) for x in args.lr_step.split(',')]
                print(f"ğŸ“‰ ä½¿ç”¨MultiStepLRï¼Œé‡Œç¨‹ç¢‘: {milestones}")
                scheduler = torch.optim.lr_scheduler.MultiStepLR(
                    optimizer,
                    milestones=milestones,
                    gamma=args.lr_gamma,
                    last_epoch=-1  # é‡ç½®last_epoch
                )
            else:
                # StepLR
                step_size = int(args.lr_step)
                print(f"ğŸ“‰ ä½¿ç”¨StepLRï¼Œæ­¥é•¿: {step_size}")
                scheduler = torch.optim.lr_scheduler.StepLR(
                    optimizer,
                    step_size=step_size,
                    gamma=args.lr_gamma,
                    last_epoch=-1
                )
        elif args.lr_scheduler == 'cosine':
            print(f"ğŸ“‰ ä½¿ç”¨CosineAnnealingLRï¼ŒT_max={args.total_epoch}")
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                optimizer,
                T_max=args.total_epoch,
                last_epoch=-1
            )
        
        # [ä¿®å¤] æ¢å¤schedulerçŠ¶æ€
        if scheduler is not None and scheduler_state_loaded and 'scheduler' in checkpoint:
            try:
                scheduler.load_state_dict(checkpoint['scheduler'])
                print(f"âœ… SchedulerçŠ¶æ€å·²æ¢å¤\n")
            except Exception as e:
                print(f"âš ï¸  Scheduleræ¢å¤å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤çŠ¶æ€\n")
        
        # 3.5 åŠ è½½æ•°æ®é›†å¯¹è±¡ï¼ˆç”¨äºéªŒè¯å’Œè®°å¿†åº“åˆå§‹åŒ–ï¼‰
        if args.dataset == 'sysu':
            from datasets.sysu import SYSU
            dataset_obj = SYSU(args)
        elif args.dataset == 'regdb':
            from datasets.regdb import RegDB
            dataset_obj = RegDB(args)
        elif args.dataset == 'llcm':
            from datasets.llcm import LLCM
            dataset_obj = LLCM(args)
        
        # 3.6 è¿›å…¥è®­ç»ƒå¾ªç¯
        from task.train import train
        train(
            model=model,
            train_loader=train_loader,
            dataset_obj=dataset_obj,
            optimizer=optimizer,
            scheduler=scheduler,
            args=args,
            device=device,
            teacher_model=teacher_model,
            start_epoch=start_epoch  # [ä¿®å¤] ä¼ é€’start_epoch
        )
    
    # ==================== 4. æµ‹è¯•æ¨¡å¼ ====================
    elif args.mode == 'test':
        if not args.model_path:
            raise ValueError("âŒ æµ‹è¯•æ¨¡å¼éœ€è¦æŒ‡å®š --model-path å‚æ•°!")
        
        print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ¨¡å‹: {args.model_path}")
        checkpoint = torch.load(args.model_path, map_location=device)
        
        # [ä¿®å¤] å…¼å®¹å¤šç§checkpoint keyæ ¼å¼
        if 'model' in checkpoint:
            model.load_state_dict(checkpoint['model'])
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (key='model')")
        elif 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (key='model_state_dict')")
        else:
            raise KeyError(
                "âŒ Checkpointä¸­æœªæ‰¾åˆ°æ¨¡å‹æƒé‡!\n"
                "   å°è¯•çš„key: 'model', 'model_state_dict'"
            )
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'epoch' in checkpoint:
            print(f"   â””â”€ Epoch: {checkpoint['epoch']}")
        if 'rank1' in checkpoint:
            print(f"   â””â”€ Rank-1: {checkpoint['rank1']:.2f}%")
        if 'mAP' in checkpoint:
            print(f"   â””â”€ mAP: {checkpoint['mAP']:.2f}%")
        print()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        if args.dataset == 'sysu':
            from datasets.sysu import SYSU
            dataset_obj = SYSU(args)
        elif args.dataset == 'regdb':
            from datasets.regdb import RegDB
            dataset_obj = RegDB(args)
        elif args.dataset == 'llcm':
            from datasets.llcm import LLCM
            dataset_obj = LLCM(args)
        
        # è¿è¡Œæµ‹è¯•
        from task.test import test
        test(
            model=model,
            query_loader=dataset_obj.query_loader,
            gallery_loaders=dataset_obj.gallery_loaders,
            args=args,
            device=device
        )


if __name__ == '__main__':
    main()
