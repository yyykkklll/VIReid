"""
task/train.py - PF-MGCDè®­ç»ƒè„šæœ¬ (å®Œæ•´ä¿®å¤ç‰ˆ)

ä¿®å¤æ—¥å¿—:
1. [P0] æ”¯æŒæ–­ç‚¹æ¢å¤start_epochå‚æ•°
2. [P0] ä¿å­˜Teacheræ¨¡å‹çŠ¶æ€åˆ°checkpoint
3. [P2] æ·»åŠ @torch.no_gradè£…é¥°å™¨é˜²æ­¢å†…å­˜æ³„æ¼
4. æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Š

åŠŸèƒ½:
- è®­ç»ƒå¾ªç¯ç®¡ç†
- EMAæ›´æ–°Teacheræ¨¡å‹
- è®°å¿†åº“åŠ¨æ€æ›´æ–°
- å®šæœŸè¯„ä¼°å’Œä¿å­˜
"""

import os
import time
import logging
import torch
import torch.nn as nn
from tqdm import tqdm

from models.loss import TotalLoss
from task.test import test

try:
    from torch.amp import autocast, GradScaler
except ImportError:
    from torch.cuda.amp import GradScaler
    from torch import autocast


def setup_logger(log_dir, log_file='train.log'):
    """
    åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    
    Args:
        log_dir: æ—¥å¿—ç›®å½•
        log_file: æ—¥å¿—æ–‡ä»¶å
    Returns:
        logger: logging.Loggerå¯¹è±¡
    """
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_file)
    
    # æ¸…ç©ºæ—§æ—¥å¿—
    if os.path.exists(log_path):
        open(log_path, 'w').close()
    
    # åˆ›å»ºlogger
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.propagate = False
    
    # æ¸…é™¤æ—§handlers
    if logger.hasHandlers():
        logger.handlers.clear()
    
    # æ–‡ä»¶handler
    fh = logging.FileHandler(log_path, mode='a')
    fh.setLevel(logging.INFO)
    fh.setFormatter(
        logging.Formatter(
            '[%(asctime)s] - %(levelname)s: %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
    )
    logger.addHandler(fh)
    
    # æ§åˆ¶å°handlerï¼ˆåªè¾“å‡ºWARNINGåŠä»¥ä¸Šï¼‰
    ch = logging.StreamHandler()
    ch.setLevel(logging.WARNING)
    ch.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(ch)
    
    return logger


@torch.no_grad()  # [ä¿®å¤] æ·»åŠ è£…é¥°å™¨ï¼Œç¡®ä¿ä¸æ„å»ºè®¡ç®—å›¾
def update_ema_variables(model, ema_model, alpha, global_step):
    """
    EMA (Exponential Moving Average) æ›´æ–°Teacheræ¨¡å‹æƒé‡
    
    Teacherå‚æ•°æ›´æ–°å…¬å¼:
    Î¸_teacher â† Î± * Î¸_teacher + (1-Î±) * Î¸_student
    
    Args:
        model: Studentæ¨¡å‹
        ema_model: Teacheræ¨¡å‹ï¼ˆEMAï¼‰
        alpha: åŠ¨é‡ç³»æ•°ï¼Œé€šå¸¸å–0.999
        global_step: å…¨å±€è®­ç»ƒæ­¥æ•°ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´alphaï¼Œå¯é€‰ï¼‰
    """
    # æ›´æ–°å¯è®­ç»ƒå‚æ•°
    for ema_param, param in zip(ema_model.parameters(), model.parameters()):
        ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)
    
    # æ›´æ–°bufferï¼ˆå¦‚BNçš„running_mean/running_varï¼‰
    for ema_buffer, buffer in zip(ema_model.buffers(), model.buffers()):
        if buffer.dtype.is_floating_point:
            # æµ®ç‚¹å‹bufferä½¿ç”¨EMAæ›´æ–°
            ema_buffer.data.mul_(alpha).add_(buffer.data, alpha=1 - alpha)
        else:
            # æ•´å‹bufferç›´æ¥å¤åˆ¶ï¼ˆå¦‚è®°å¿†åº“çš„initializedæ ‡è®°ï¼‰
            ema_buffer.data.copy_(buffer.data)


def train_one_epoch(model, train_loader, criterion, optimizer, scaler, 
                    device, epoch, logger, args, teacher_model=None):
    """
    å•ä¸ªepochçš„è®­ç»ƒ
    
    Args:
        model: Studentæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        scaler: AMPçš„GradScalerï¼ˆæ··åˆç²¾åº¦è®­ç»ƒï¼‰
        device: è®¡ç®—è®¾å¤‡
        epoch: å½“å‰epochç´¢å¼•
        logger: æ—¥å¿—è®°å½•å™¨
        args: è¶…å‚æ•°é…ç½®
        teacher_model: Teacheræ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        avg_loss_dict: Dictï¼Œå¹³å‡æŸå¤±å­—å…¸
    """
    model.train()
    if teacher_model:
        teacher_model.train()  # BNå±‚éœ€è¦trainæ¨¡å¼
    
    # æŸå¤±ç»Ÿè®¡
    total_loss = 0
    loss_items = {'loss_id': 0, 'loss_triplet': 0, 'loss_graph': 0}
    
    # è¿›åº¦æ¡
    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.total_epoch}')
    
    for batch_idx, batch_data in enumerate(pbar):
        # 1. æ•°æ®è§£åŒ…ï¼ˆå…¼å®¹å¤šç§æ ¼å¼ï¼‰
        if len(batch_data) == 3:
            images, labels, cams = batch_data
            images = images.to(device)
            labels = labels.to(device)
            cams = cams.to(device)
            modality_labels = (cams >= 3).long()  # å‡è®¾cam>=3ä¸ºçº¢å¤–
        else:
            # å…¶ä»–æ ¼å¼
            images, labels = batch_data[:2]
            images = images.to(device)
            labels = labels.to(device)
        
        # 2. æ¸…ç©ºæ¢¯åº¦
        optimizer.zero_grad()
        
        # 3. å‰å‘ä¼ æ’­ + åå‘ä¼ æ’­
        if args.amp and scaler is not None:
            # [æ··åˆç²¾åº¦è®­ç»ƒ] ä½¿ç”¨FP16åŠ é€Ÿ
            with autocast(device_type='cuda'):
                outputs = model(images, labels=labels)
                loss, loss_dict = criterion(outputs, labels, current_epoch=epoch)
            
            # ç¼©æ”¾æŸå¤±å¹¶åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            if args.grad_clip > 0:
                scaler.unscale_(optimizer)  # å…ˆunscaleæ‰èƒ½è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            
            # æ›´æ–°å‚æ•°
            scaler.step(optimizer)
            scaler.update()
        else:
            # [FP32è®­ç»ƒ] æ ‡å‡†æµç¨‹
            outputs = model(images, labels=labels)
            loss, loss_dict = criterion(outputs, labels, current_epoch=epoch)
            loss.backward()
            
            if args.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            
            optimizer.step()
        
        # 4. EMAæ›´æ–°Teacheræ¨¡å‹
        if teacher_model:
            global_step = epoch * len(train_loader) + batch_idx
            update_ema_variables(model, teacher_model, alpha=0.999, global_step=global_step)
        
        # 5. ç»Ÿè®¡æŸå¤±
        total_loss += loss.item()
        for key in loss_items.keys():
            if key in loss_dict:
                loss_items[key] += loss_dict[key]
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'Loss': f'{loss.item():.4f}',
            'ID': f'{loss_dict.get("loss_id", 0):.4f}',
            'Graph': f'{loss_dict.get("loss_graph", 0):.4f}'
        })
        
        # 6. [æ ¸å¿ƒ] æ›´æ–°è®°å¿†åº“ï¼ˆWarmupåå¯ç”¨ï¼‰
        # ä¿®å¤å (task/train.py)
        if epoch >= args.warmup_epochs:
            with torch.no_grad():
                if 'id_features' in outputs:
                    # [ä¿®å¤] æ˜¾å¼detachç‰¹å¾ï¼Œç¡®ä¿å®Œå…¨åˆ‡æ–­è®¡ç®—å›¾
                    detached_features = [feat.detach() for feat in outputs['id_features']]
                    model.memory_bank.update_memory(detached_features, labels)

    
    # è®¡ç®—å¹³å‡æŸå¤±
    num_batches = len(train_loader)
    avg_loss_dict = {k: v / num_batches for k, v in loss_items.items()}
    avg_loss_dict['loss_total'] = total_loss / num_batches
    
    return avg_loss_dict


def train(model, train_loader, dataset_obj, optimizer, scheduler, args, device,
          teacher_model=None, start_epoch=0):
    """
    è®­ç»ƒä¸»å‡½æ•°
    
    Args:
        model: Studentæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        dataset_obj: æ•°æ®é›†å¯¹è±¡ï¼ˆç”¨äºéªŒè¯ï¼‰
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        args: è¶…å‚æ•°é…ç½®
        device: è®¡ç®—è®¾å¤‡
        teacher_model: Teacheræ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        start_epoch: [ä¿®å¤] æ–­ç‚¹æ¢å¤çš„èµ·å§‹epoch
    """
    # åˆ›å»ºä¿å­˜ç›®å½•å’Œæ—¥å¿—
    os.makedirs(args.save_dir, exist_ok=True)
    os.makedirs(args.log_dir, exist_ok=True)
    logger = setup_logger(args.log_dir)
    
    logger.info(f"ğŸ“ Save Dir: {args.save_dir}")
    logger.info(f"ğŸ“Š Training: Epoch {start_epoch+1} ~ {args.total_epoch}")
    
    # 1. åˆå§‹åŒ–è®°å¿†åº“ï¼ˆä»…åœ¨ä»å¤´è®­ç»ƒæ—¶ï¼‰
    if start_epoch == 0 and args.init_memory:
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–è®°å¿†åº“...")
        normal_rgb_loader, _ = dataset_obj.get_normal_loader()
        model.initialize_memory(normal_rgb_loader, device, teacher_model=None)
        logger.info("âœ… è®°å¿†åº“åˆå§‹åŒ–å®Œæˆ")
    
    # 2. åˆ›å»ºæŸå¤±å‡½æ•°
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ (Epoch {start_epoch+1} ~ {args.total_epoch})...")
    criterion = TotalLoss(
        num_parts=args.num_parts,
        lambda_graph=args.lambda_graph,
        lambda_triplet=getattr(args, 'lambda_triplet', 1.0),
        label_smoothing=args.label_smoothing,
        start_epoch=20  # Graph Losså¯åŠ¨epoch
    ).to(device)
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler(device='cuda') if args.amp else None
    
    # æœ€ä½³æ¨¡å‹è·Ÿè¸ª
    best_rank1 = 0.0
    
    # 3. [ä¿®å¤] ä»start_epochå¼€å§‹è®­ç»ƒ
    for epoch in range(start_epoch, args.total_epoch):
        start_time = time.time()
        
        # è®­ç»ƒä¸€ä¸ªepoch
        avg_losses = train_one_epoch(
            model, train_loader, criterion, optimizer, scaler,
            device, epoch, logger, args, teacher_model
        )
        
        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler:
            scheduler.step()
        
        # è®°å½•æ—¥å¿—
        epoch_time = time.time() - start_time
        curr_lr = optimizer.param_groups[0]['lr']
        logger.info(f"Epoch {epoch+1}/{args.total_epoch} [â±ï¸ {epoch_time:.1f}s, ğŸ“‰ LR: {curr_lr:.6f}]")
        logger.info(
            f"  Loss: {avg_losses['loss_total']:.4f} "
            f"(ID: {avg_losses['loss_id']:.4f}, "
            f"Triplet: {avg_losses.get('loss_triplet', 0):.4f}, "
            f"Graph: {avg_losses.get('loss_graph', 0):.4f})"
        )
        
        # 4. [ä¿®å¤] ä¿å­˜checkpointï¼ˆåŒ…å«TeacherçŠ¶æ€ï¼‰
        if (epoch + 1) % args.save_epoch == 0:
            checkpoint = {
                'epoch': epoch + 1,
                'model': model.state_dict(),
                'optim': optimizer.state_dict(),
                'scheduler': scheduler.state_dict() if scheduler else None,
                'teacher': teacher_model.state_dict() if teacher_model else None,
                'best_rank1': best_rank1,
                'args': vars(args)
            }
            save_path = os.path.join(args.save_dir, f'epoch_{epoch+1}.pth')
            torch.save(checkpoint, save_path)
            logger.info(f"ğŸ’¾ Checkpoint saved: {save_path}")
        
        # 5. å®šæœŸè¯„ä¼°
        if (epoch + 1) % args.eval_epoch == 0:
            print(f"\nğŸ“Š è¯„ä¼°æ¨¡å‹ (Epoch {epoch+1})...")
            logger.info("ğŸ” å¼€å§‹è¯„ä¼°...")
            
            # è°ƒç”¨æµ‹è¯•å‡½æ•°
            rank1, mAP, mINP = test(
                model, 
                dataset_obj.query_loader,
                dataset_obj.gallery_loaders,
                args,
                device
            )
            
            logger.info(f"ğŸ“ˆ Validation: Rank-1={rank1:.2f}%, mAP={mAP:.2f}%, mINP={mINP:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if rank1 > best_rank1:
                best_rank1 = rank1
                best_checkpoint = {
                    'epoch': epoch + 1,
                    'model': model.state_dict(),
                    'teacher': teacher_model.state_dict() if teacher_model else None,
                    'rank1': rank1,
                    'mAP': mAP,
                    'mINP': mINP
                }
                torch.save(best_checkpoint, os.path.join(args.save_dir, 'best_model.pth'))
                logger.info(f"ğŸ† New Best Model! (Rank-1: {best_rank1:.2f}%)")
            
            # æ¢å¤è®­ç»ƒæ¨¡å¼
            model.train()
    
    logger.info("âœ… è®­ç»ƒå®Œæˆ!")
    print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
